# 深層学習 Day3, 4
## 要点のまとめ

#### Day3-1.再帰型ニューラルネットワーク(RNN)の概念

* RNNとは  
  ・時系列データに対応可能なNNのこと。  
  ・時系列データ：音声データ、テキストデータ、株価チャートなど  
  　時間順序に剃って観測され、それらに統計的相互関係が認められるデータのこと。
  
  ・ポイントは中間層にある。  
  　前回に中間層で出力された値を、次の入力に加える機構(再帰的)をもつ。  

* RNNの数学モデル  
  <img src="https://latex.codecogs.com/gif.latex?u^{t}=W_{(in)}x^{t}&plus;Wz^{t-1}&plus;b" title="u^{t}=W_{(in)}x^{t}+Wz^{t-1}+b" />  
  <img src="https://latex.codecogs.com/gif.latex?z^{t}=f\left&space;(&space;W_{(in)}x^{t}&plus;Wz^{t-1}&plus;b&space;\right&space;)" title="z^{t}=f\left ( W_{(in)}x^{t}+Wz^{t-1}+b \right )" />  
  　<img src="https://latex.codecogs.com/gif.latex?v^{t}=W_{(out)}z^{t}&plus;c" title="v^{t}=W_{(out)}z^{t}+c" />  
  　<img src="https://latex.codecogs.com/gif.latex?y^{t}=g\left&space;(&space;W_{(out)}z^{t}&plus;c&space;\right&space;)" title="y^{t}=g\left ( W_{(out)}z^{t}+c \right )" />  

* RNNの特徴  
  ・初期の状態と過去の時刻t-1の状態を保持し、そこから次の時刻tでの状態を再帰的に求める構造をもつ。  

* BPTT (Back Propegation Through Time)  
  ・RNNにおけるパラメータ調整法の一種。  
  ・誤差逆伝播法の一種。  

* BPTTの数学モデル  
  ・入力層→中間層  
  　<img src="https://latex.codecogs.com/gif.latex?\frac{\partial&space;E}{\partial&space;W_{(in)}}=\frac{\partial&space;E}{\partial&space;u^{t}}\left&space;[&space;\frac{\partial&space;u^{t}}{\partial&space;W_{(in)}}&space;\right&space;]^{T}=\delta&space;^{t}\left&space;[&space;x^{t}&space;\right&space;]^{T}" title="\frac{\partial E}{\partial W_{(in)}}=\frac{\partial E}{\partial u^{t}}\left [ \frac{\partial u^{t}}{\partial W_{(in)}} \right ]^{T}=\delta ^{t}\left [ x^{t} \right ]^{T}" />  
  ・中間層→出力層  
  　<img src="https://latex.codecogs.com/gif.latex?\frac{\partial&space;E}{\partial&space;W_{(out)}}=\frac{\partial&space;E}{\partial&space;v^{t}}\left&space;[&space;\frac{\partial&space;v^{t}}{\partial&space;W_{(out)}}&space;\right&space;]^{T}=\delta&space;^{out,t}\left&space;[&space;z^{t}&space;\right&space;]^{T}" title="\frac{\partial E}{\partial W_{(out)}}=\frac{\partial E}{\partial v^{t}}\left [ \frac{\partial v^{t}}{\partial W_{(out)}} \right ]^{T}=\delta ^{out,t}\left [ z^{t} \right ]^{T}" />  
  ・中間層(t-1)→中間層(t)  
  　<img src="https://latex.codecogs.com/gif.latex?\frac{\partial&space;E}{\partial&space;W}=\frac{\partial&space;E}{\partial&space;u^{t}}\left&space;[&space;\frac{\partial&space;u^{t}}{\partial&space;W}&space;\right&space;]^{T}=\delta&space;^{t}\left&space;[&space;z^{t-1}&space;\right&space;]^{T}" title="\frac{\partial E}{\partial W}=\frac{\partial E}{\partial u^{t}}\left [ \frac{\partial u^{t}}{\partial W} \right ]^{T}=\delta ^{t}\left [ z^{t-1} \right ]^{T}" />  
  ・バイアス項1  
  　<img src="https://latex.codecogs.com/gif.latex?\frac{\partial&space;E}{\partial&space;b}=\frac{\partial&space;E}{\partial&space;u^{t}}\frac{\partial&space;u^{t}}{\partial&space;b}=\delta&space;^{t}" title="\frac{\partial E}{\partial b}=\frac{\partial E}{\partial u^{t}}\frac{\partial u^{t}}{\partial b}=\delta ^{t}" />  
  ・バイアス項2  
  　<img src="https://latex.codecogs.com/gif.latex?\frac{\partial&space;E}{\partial&space;c}=\frac{\partial&space;E}{\partial&space;v^{t}}\frac{\partial&space;v^{t}}{\partial&space;c}=\delta&space;^{out,t}" title="\frac{\partial E}{\partial c}=\frac{\partial E}{\partial v^{t}}\frac{\partial v^{t}}{\partial c}=\delta ^{out,t}" />  
   
* BPTTによるパラメータ更新式  
  <img src="https://latex.codecogs.com/gif.latex?W_{(in)}^{t&plus;1}=W_{(in)}^{t}-\epsilon&space;\frac{\partial&space;E}{\partial&space;W_{(in)}}=W_{(in)}^{t}-\epsilon&space;\sum_{z=0}^{T_{t}}\delta&space;^{t-z}\left&space;[&space;x^{t-z}&space;\right&space;]^{T}" title="W_{(in)}^{t+1}=W_{(in)}^{t}-\epsilon \frac{\partial E}{\partial W_{(in)}}=W_{(in)}^{t}-\epsilon \sum_{z=0}^{T_{t}}\delta ^{t-z}\left [ x^{t-z} \right ]^{T}" />  
  <img src="https://latex.codecogs.com/gif.latex?W_{(out)}^{t&plus;1}=W_{out}^{t}-\epsilon&space;\frac{\partial&space;E}{\partial&space;W_{(out)}}=W_{(out)}^{t}-\epsilon&space;\delta&space;^{out,t}\left&space;[&space;z^{t}&space;\right&space;]^{T}" title="W_{(out)}^{t+1}=W_{out}^{t}-\epsilon \frac{\partial E}{\partial W_{(out)}}=W_{(out)}^{t}-\epsilon \delta ^{out,t}\left [ z^{t} \right ]^{T}" />  
  <img src="https://latex.codecogs.com/gif.latex?W^{t&plus;1}=W^{t}-\epsilon&space;\frac{\partial&space;E}{\partial&space;W}=W_{(in)}^{t}-\epsilon&space;\sum_{z=0}^{T_{t}}\delta&space;^{t-z}\left&space;[&space;z^{t-z-1}&space;\right&space;]^{T}" title="W^{t+1}=W^{t}-\epsilon \frac{\partial E}{\partial W}=W_{(in)}^{t}-\epsilon \sum_{z=0}^{T_{t}}\delta ^{t-z}\left [ z^{t-z-1} \right ]^{T}" />  
  <img src="https://latex.codecogs.com/gif.latex?b^{t-1}=b^{t}-\epsilon&space;\frac{\partial&space;E}{\partial&space;b}=b^{t}-\epsilon&space;\sum_{z=0}^{T_{t}}\delta&space;^{t-z}" title="b^{t-1}=b^{t}-\epsilon \frac{\partial E}{\partial b}=b^{t}-\epsilon \sum_{z=0}^{T_{t}}\delta ^{t-z}" />  
  <img src="https://latex.codecogs.com/gif.latex?c^{t-1}=c^{t}-\epsilon&space;\frac{\partial&space;E}{\partial&space;c}=c^{t}-\epsilon&space;\delta&space;^{out,t}" title="c^{t-1}=c^{t}-\epsilon \frac{\partial E}{\partial c}=c^{t}-\epsilon \delta ^{out,t}" />  


#### Day3-2.LSTM

* RNNの課題  
  ・時系列を遡るほど勾配が消失していく。  
  　そのため、長い時系列データの学習が困難。  
  
* LSTMの全体像  
  ![](/image/DNN_Day3/1.png.png)
  
* CEC  
  ・勾配消失、勾配爆発の解決策として勾配が1出あればよいという発想。  
  　<img src="https://latex.codecogs.com/gif.latex?\delta&space;^{t-z-1}=\delta&space;^{t-z}\left&space;\{&space;Wf^{\,'}(u^{t-z-1})&space;\right&space;\}=1" title="\delta ^{t-z-1}=\delta ^{t-z}\left \{ Wf^{\,'}(u^{t-z-1}) \right \}=1" />  
   <img src="https://latex.codecogs.com/gif.latex?\frac{\partial&space;E}{\partial&space;c^{t-1}}=\frac{\partial&space;E}{\partial&space;c^{t}}\frac{\partial&space;c^{t}}{\partial&space;c^{t-1}}=\frac{\partial&space;E}{\partial&space;c^{t}}\&space;\frac{\partial&space;}{\partial&space;c^{t-1}}\left&space;\{&space;a^{t}-c^{t-1}&space;\right&space;\}=\frac{\partial&space;E}{\partial&space;c^{t}}" title="\frac{\partial E}{\partial c^{t-1}}=\frac{\partial E}{\partial c^{t}}\frac{\partial c^{t}}{\partial c^{t-1}}=\frac{\partial E}{\partial c^{t}}\ \frac{\partial }{\partial c^{t-1}}\left \{ a^{t}-c^{t-1} \right \}=\frac{\partial E}{\partial c^{t}}" />  
   
  ・課題
  　時間依存度に関わらず重みが一律になってしまう。(NNの学習特性がなくなる)  
  　入力ゲート、出力ゲートを導入することで解決を図る。  
   
* 入力ゲート・出力ゲート  
  ・入力・出力ゲートを追加することで、それぞれのゲートへの入力値の重みを重み行列W, Uで可変可能とする。  
  ・CECで重みが一律になる課題を解決。  

* 忘却ゲート  
  ・CECの問題点として、過去の情報を全て保持する特性からいつまで経っても古い情報の影響を切り離せない問題点があった。  
  ・過去のデータが不要になったタイミングで情報を忘却する、忘却ゲートを導入することで解決を図った。  

* 覗き穴結合  
  ・CECに保存されている過去の情報を任意のタイミングで他のノードに伝播させたり、忘却させたりしたいニーズがあった。  
  　(そもそもCECのもつ値がゲート制御に活かせる構造をしていなかった。)  
  ・CEC自身の値を重みを介して伝播可能にした構造をもつ、覗き穴結合を用いて解決を図った。  

#### Day3-3.GRU

* LSTMの課題  
  ・パラメータが多く、それによって計算コストが大きくなってしまう。  

* GRUとは  
  ・Gated Recurrent Unit のこと。
  ・LSTMのパラメータを大幅に削減し、尚且つ同等以上の精度が見込める構造をしている。  
  ・メリット  
  　LSTMに比べ計算負荷が小さい。  
   
* GRUの全体像
  ![](/image/DNN_Day3/2.png)

#### Day3-4.双方向RNN

* 双方向RNNとは  
  ・過去の情報だけでなく、未来の情報を加味することで精度をあげたRNNの派生モデル。  
  ・入力層、中間層の順方向伝播は通常のRNNと変わらない。  
  ・出力層では時系列的に逆方向(未来から過去)の部分と結合される。  
  ・文章の推敲や翻訳に使用される。  

#### Day3-5.Seq2Seq

* Seq2Seqとは  
  ・Encoder-Decoderモデルの一種。  
  ・機械対話や機械翻訳に使われている。  
  
* Encoder RNN  
  ・ユーザーが入力したテストデータを単語などのトークンに区切って渡す構造。  
  ・Toking：文章をトークンに分割し、トークンごとのIDに分割する。  
  ・Embedding：IDから、それを表す分散表現ベクトルに変換する。  
  ・Encoder RNN：ベクトルを順にRNNに入力していく。  
  ・処理手順  
  　(1) vec1をRNNに入力 → hidden stateを出力 → vec2をRNNに入力 → hidden stateを出力 → (繰り返し)  
  　(2) 最後のvecを入力したときのhidden stateをfinal stateとしてとっておく。  
   　　　これがthought vectorと呼ばれ、入力文を意味するベクトルとなる。  
      
* Decoder RNN  
  ・システムが出力データをトークンごとに生成する構造。  
  ・処理手順  
  　(1) Encoder RNNの出力から、各トークンの生成確率を出力していく。  
  　(2) 生成確率に基づいてトークンをランダムに生成する。(sampling)  
  　(3) 2で選ばれたトークンをEmbeddingしてDecoder RNNの次の入力とする。(Embedding)  
  　(4) 1〜3を繰り返して2で得られたトークンを文字列に直す。(Detokenize)  
   
* HRED  
  ・Seq2Seqの課題  
  　一問一答しかできない。(FAQのような)  
  　文脈がなく、ただ応答が行われる。(空気を読むようなことができない)  
  
  ・HREDの特徴  
  　過去n-1個の会話から次の発話が生成される。  
  　HRED = Seq2Seq + ContextRNN  
  　ただし、会話の流れは表現できない。(同じコンテキストを与えられると、毎回同じ返答になる。)  
  　また、返答は短いものになりがち。(うん、そうだね、など)  
   
* VHRED  
  ・HREDにVAEの潜在変数の概念を追加したもの。  
  ・HREDの課題を解決。(特に同じ返答しかできないところに対応)  
  
* オートエンコーダ(AE)  
  ・教師なし学習の１つ。  
  ・入力と同じ結果を出力する。  
  ・構造  
  　エンコーダ：入力データを潜在変数zへ変換する。  
  　デコーダ：zを入力データに変換する。  
  ・変換の過程で時限削減できるメリットがある。(情報量を削ぎ落とす)  
  
* VAE  
  ・AEは潜在変数の構造がブラックボックス。  
  ・VAEでは潜在変数に確率分布z~N(0,1)を仮定している。  
  ・少なくとも確率分布の構造に落とし込めるようになった。  

#### Day3-6.Word2vec

* Word2vecとは  
  ・RNNでは単語の文字列などの可変長のデータをNNに与えられなかった。(固定長でないとダメ)  
  ・特徴  
  　学習データからボキャブラリを作成する。
  　入力された文章から単語を切り分け、それらを記憶する。  
  ・メリット  
  　大規模データの分散表現の学習が、現実的なメモリ量と計算速度でできるようになった。  
  　　従来：(ボキャブラリ数)\*(ボキャブラリ数)だけの重み行列が必要。  
  　　Word2vec：(ボキャブラリ数)\*(任意の単語ベクトル)だけの重み行列が必要。  
  　　→精度を下げずにデータ量を大幅に抑えられる。

#### Day3-7.Attention Mechanism

* Attention Mechanism とは  
  ・Seq2Seqは長文への対応が難しかった。(入力が何語であっても固定次元のベクトルに入力する必要があった。)  
  ・入力が長いほど、シーケンスの内部表現の次元数を動的に大きくする仕組みが必要。  
  　→ Attention Mechanism の提案  
  ・「入力と出力のどの単語が関連しているのか」という関連度を学習する仕組みを持つ。  


#### Day4-1.強化学習

* 強化学習とは  
  ・長期的に利益を最大化できるように、環境の中で適切な行動を選択できる  
  　エージェントを作ることを目標とする機械学習分野の1つ。  
  ・行動の結果として与えられる利益(報酬)を基に、行動決定の原理を改善していく仕組みを持つ。  
  
* 強化学習の応用例  
　・囲碁や将棋などのゲームプレイ  
　・自動運転システム  
　・ロボットアームの操作  
 　など
  
* 探索と利用のトレードオフ  
　・事前に完璧な知識がない以上、最初はランダムに動く(探索)必要がある。  
 　次第に過去の経験を活かして(利用)行動していくことが望ましい。  
  ・探索と利用はトレードオフの関係  
  　探索ばかりだと：過去の経験を活かせない。  
  　利用ばかりだと：他のベストな方法を見つけられない。  
  ・バランスをとるためのアプローチがいくつか提案されている。(ex. ε-greedyメソッド)  
   
* 強化学習の数学モデル化  
  ・学習ポイントは「方策」と「報酬」の2つ。  
  　方策関数 <img src="https://latex.codecogs.com/gif.latex?\prod&space;(s,a)" title="\prod (s,a)" /> ：行動を決める指針となる関数。  
  　行動価値関数 <img src="https://latex.codecogs.com/gif.latex?Q(s,a)" title="Q(s,a)" /> ：報酬の良し悪しを判断する関数。  
  
* 強化学習の歴史  
　・考え方自体は昔からあったが、リソース不足でうまくいってなかった。  
　・近年のマシンスペックの向上 + 関数近似法とQ学習の組合せの台頭により発展することになった。  
 
* 価値関数  
  ・価値の決め方をに関わる関数。  
  ・状態価値関数と行動価値関数の２種類がある。  
  　状態価値関数：ある状態の価値に注目。状態にのみ依存して価値が決まる。  
  　行動価値関数：状態+行動で価値を決める。  

* 方策関数  
  ・行動の決め方に関わる関数。  
  ・ある状態でどんな行動を採るべきかを確率で与える。  
  
* 方策勾配法  
  ・方策反復法：方策をモデル化して最適化する手法。  
  ・方策勾配法  
  　<img src="https://latex.codecogs.com/gif.latex?\theta&space;^{t&plus;1}&space;=&space;\theta&space;^{t}&plus;\epsilon&space;\triangledown&space;J(\theta&space;)" title="\theta ^{t+1} = \theta ^{t}+\epsilon \triangledown J(\theta )" />  
  　θ：NNでいう重み、J(θ)：NNでいう誤差関数  
  ・J(θ)の定義  
  　手法：平均報酬or割引報酬  
   
  ・行動価値関数Q(s,a)の定義ができれば、以下の方策勾配定理が成り立つ。  
  　<img src="https://latex.codecogs.com/gif.latex?\nabla_{\theta&space;}J(\theta&space;)=E_{\pi&space;_{\theta&space;}}\left&space;[&space;\nabla_{\theta&space;}log\pi&space;_{\theta&space;}(a\mid&space;s)Q^{\pi&space;}(s,a)&space;\right&space;]" title="\nabla_{\theta }J(\theta )=E_{\pi _{\theta }}\left [ \nabla_{\theta }log\pi _{\theta }(a\mid s)Q^{\pi }(s,a) \right ]" />  
  
#### Day4-2.AlphaGo

* AlphaGo Lee  
  ・基本はCNN  
  ・PolicyとValue用に2つのネットワークを持つ。  
  ・PolicyNet  
  　入力は19\*19\*48 (碁盤の目と１マスの持つ情報量の組合せ)  
  　LeRU + SoftMax  
  　出力は19\*19マスの着手予想確率(2次元)  
  　→ エージェントにどこに打てば良いのかを伝える。  
   
  ・ValueNet  
  　入力は19\*19\*49 (手番情報が１つ分増える)  
  　ReLU + tanh
  　出力は-1〜1 (現局面での勝率)  

* AlphaGoの学習  
  (1) いきなり強化学習ではなく、教師あり学習でRolloutPolicyとPolicyNetを学習。(人と打って定石を学習)  
  (2) 強化学習でPolicyNetの学習。  
  (3) 強化学習でValueNetの学習。  
  
* RolloutPolicy  
  ・NNではなく、線型の方策関数  
  ・探索中に高速に着手確率を計算するために使用される。(パフォーマンス重視の設計、NNより1000倍ほど早い)  
  
* モンテカルロ木探索  
  ・価値関数の学習時に用いる手法。  
  ・その時点での盤面での評価が難しいので、最終局面まで見て評価を行うアルゴリズム。  
  
* AlphaGo Zero  
  ・Leeとの違い  
  　強化学習のみで学習する。  
  　特徴入力は石の配置のみ。  
  　policyNetとValueNetを１つに統合  
  　ResidualNetの導入  
  　モンテカルロ木探索からRolloutシミュレーションを削除  
   
* Residual Network  
  ・ネットワークが深くなると勾配消失が起きやすくなるため、ショートカットできる別ルートを(Residual構造)もったモデル。  
  ・これにより100層超えのネットワークへの対応が可能。  

* Residual Network の派生形  
  ・Residual Blockの工夫 (BottleNeck, PreActivation)  
  ・Network構造の工夫 (WideResNet, PyramidNet)
  
#### Day4-3.データ並列化

* データ並列化とは
  ・分散深層学習の手法の1つ  
  ・親モデルを各ワーカーに子モデルとしてコピー、データを分割し各ワーカーごとに計算を行う。  
  ・モデルをたくさん用意して、手分けして学習を進めるイメージ。

* 同期型・非同期型  
  ・同期型：全ワーカーの計算が終わるまで待ち、終わるたび子の計算結果の平均を親に反映する。  
  ・非同期型：パラメータサーバーを別に用意し、角ワーカーは自分の計算が終わるとサーバーに結果をあげる。  
   　　　　　その後、最新のパラメータを受け取りすぐに次の計算を始める。  
  ・待ちの発生しない非同期型の方が早い。  
  　ただし、最新モデルのパラメータを使用できないので学習が不安定になりやすい。  
  　現在は精度が高いこともあって、同期型が主流。  

#### Day4-4.モデル並列化

* 


#### Day4-5.量子化

* 


#### Day4-6.蒸留

* 


#### Day4-7.プルーニング

* 


#### Day4-8.MobileNet

* 


#### Day4-9.DenseNet

* 


#### Day4-10.BatchNorm

* 


#### Day4-11.LayerNorm

* 


#### Day4-12.WaveNet

* 


#### Day4-13.Seq2seq

* 


#### Day4-14.Transformer

* 


#### Day4-15.物体検知

* 


#### Day4-16.セグメンテーション

* 


<br>

## 確認テスト

#### Day3

* PDF スライド11  
  ・自身の考察  
  　<img src="https://latex.codecogs.com/gif.latex?H=\frac{5-3&plus;1*2}{2}&plus;1=3" title="H=\frac{5-3+1*2}{2}+1=3" />  
  　<img src="https://latex.codecogs.com/gif.latex?W=\frac{5-3&plus;1*2}{2}&plus;1=3" title="W=\frac{5-3+1*2}{2}+1=3" />  

* PDF スライド23  
  ・自身の考察  
  　現在の中間層に前回の中間層の出力を加える際にかけられる重み。  

* PDF スライド36  
  ・自身の考察  
  　<img src="https://latex.codecogs.com/gif.latex?\frac{\mathrm{d}&space;z}{\mathrm{d}&space;x}=\frac{\mathrm{d}&space;z}{\mathrm{d}&space;t}\cdot&space;\frac{\mathrm{d}&space;t}{\mathrm{d}&space;x}=2t\cdot&space;1=2(x&plus;y)" title="\frac{\mathrm{d} z}{\mathrm{d} x}=\frac{\mathrm{d} z}{\mathrm{d} t}\cdot \frac{\mathrm{d} t}{\mathrm{d} x}=2t\cdot 1=2(x+y)" />  

* PDF スライド45  
  ・自身の考察  
  　<img src="https://latex.codecogs.com/gif.latex?y_{1}=g\left&space;(&space;w_{out}\cdot&space;g\left&space;(&space;w_{in}&space;x&space;&plus;ws_{0}&plus;b\right&space;)&plus;c&space;\right&space;)" title="y_{1}=g\left ( w_{out}\cdot g\left ( w_{in} x +ws_{0}+b\right )+c \right )" />  

* PDF スライド62  
  ・自身の考察  
  　<img src="https://latex.codecogs.com/gif.latex?sigmoid^{\,'}(u)=\left&space;(&space;1-sigmoid(u)&space;\right&space;)\cdot&space;sigmoid(u)" title="sigmoid^{\,'}(u)=\left ( 1-sigmoid(u) \right )\cdot sigmoid(u)" />,  
  　<img src="https://latex.codecogs.com/gif.latex?sigmoid\,(0)=\frac{1}{2}" title="sigmoid\,(0)=\frac{1}{2}" />  
   <br>
  　<img src="https://latex.codecogs.com/gif.latex?\therefore&space;sigmoid^{\,'}(0)=0.25" title="\therefore sigmoid^{\,'}(0)=0.25" />  

* PDF スライド78  
  ・自身の考察  
  　予測に不要なデータを消去する → 忘却ゲート  

* PDF スライド88  
  ・自身の考察  
  　LSTMの課題：パラメータ数が多いため計算コストが大きい。  
  　CECの課題：入力・出力ゲートに対して値のフィードバックができない。  
   　　　　　　過去のデータを全て保持するため、不要なデータがいつもでも残ってしまう。  
        　　　勾配が１のため、学習が行えない。  

* PDF スライド92  
  ・自身の考察  
  　GRUはパラメータ数がLSTMと比べて少ない。  

* PDF スライド109  
  ・自身の考察  
  　(1) 双方向RNN  
  　(2) Seq2Seq  
  　(3) Word2seq  
  　(4) LSTM  

* PDF スライド119  
  ・自身の考察  
  　Seq2Seq：一問一答しか対応できない。  
  　HRED：過去の発言も考慮できるが、同じコンテキストに対して毎回同じ答えになる。  
  　VHRED：HREDにVAEの潜在変数を追加したもの。文脈を考慮し、異なる表現で返答できる。  

* PDF スライド128  
  ・自身の考察  
  　VAEは自己符号化器の潜在変数に「確率分布」の概念を加えたもの。  

* PDF スライド137  
  ・自身の考察  
  　RNNとword2vecの違い  
  　　単語の文字列のような可変長のデータを扱えるかどうか。  
  　　重みの生成の仕方が異なる。  
  　Seq2SeqとAttentionの違い  
  　　入力データが長くなっても対応できるか否か。(Attentionは可)  
    
<br>

## 実装演習結果

[DNN_Day3 実装演習結果](/practice/実装演習_DNN_Day3.md)  
